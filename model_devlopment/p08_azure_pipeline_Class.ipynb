{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb2b85c7",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Connection-to-Azure-ws\" data-toc-modified-id=\"Connection-to-Azure-ws-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Connection to Azure ws</a></span></li><li><span><a href=\"#Define-Datastore\" data-toc-modified-id=\"Define-Datastore-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Define Datastore</a></span></li><li><span><a href=\"#Create-environment\" data-toc-modified-id=\"Create-environment-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Create environment</a></span></li><li><span><a href=\"#Compute-cluster\" data-toc-modified-id=\"Compute-cluster-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Compute cluster</a></span></li><li><span><a href=\"#Script\" data-toc-modified-id=\"Script-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Script</a></span></li><li><span><a href=\"#Pipiline\" data-toc-modified-id=\"Pipiline-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Pipiline</a></span><ul class=\"toc-item\"><li><span><a href=\"#Config\" data-toc-modified-id=\"Config-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Config</a></span></li><li><span><a href=\"#Step\" data-toc-modified-id=\"Step-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Step</a></span></li><li><span><a href=\"#build-pipeline\" data-toc-modified-id=\"build-pipeline-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>build pipeline</a></span></li><li><span><a href=\"#Examine\" data-toc-modified-id=\"Examine-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Examine</a></span></li><li><span><a href=\"#Publish-pipeline\" data-toc-modified-id=\"Publish-pipeline-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Publish pipeline</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83217fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (pyOpenSSL 20.0.1 (d:\\anaconda\\lib\\site-packages), Requirement.parse('pyopenssl<20.0.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyOpenSSL 20.0.1 (d:\\anaconda\\lib\\site-packages), Requirement.parse('pyopenssl<20.0.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (pyOpenSSL 20.0.1 (d:\\anaconda\\lib\\site-packages), Requirement.parse('pyopenssl<20.0.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (pyOpenSSL 20.0.1 (d:\\anaconda\\lib\\site-packages), Requirement.parse('pyopenssl<20.0.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (pyOpenSSL 20.0.1 (d:\\anaconda\\lib\\site-packages), Requirement.parse('pyopenssl<20.0.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (pyOpenSSL 20.0.1 (d:\\anaconda\\lib\\site-packages), Requirement.parse('pyopenssl<20.0.0')).\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4601db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core import Environment, ScriptRunConfig, Experiment\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd4726",
   "metadata": {},
   "source": [
    "## Connection to Azure ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5af7b4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.19.0 to work with projet_7\n"
     ]
    }
   ],
   "source": [
    "#import workspace from config.json\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced61da",
   "metadata": {},
   "source": [
    "## Define Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "457e371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec45fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be023e22",
   "metadata": {},
   "source": [
    "## Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb7067ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create environment from yml file\n",
    "env_p8 = Environment.from_conda_specification(\"env_p8\", 'env-p8.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce0e4d6",
   "metadata": {},
   "source": [
    "## Compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7cd9909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "cluster_name = 'cluster-projet7'\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e731ce",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e45cdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_azure/data_prep_class.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_azure/data_prep_class.py\n",
    "\n",
    "print('print importing lib...')\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "from azureml.core import Dataset\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import joblib\n",
    "from class_recommender import Recommender\n",
    "from scipy import sparse\n",
    "\n",
    "print('lib imported...')\n",
    "\n",
    "#get scripts arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--input-data', type=str, dest='dataset_folder')\n",
    "#outfolder for preprocessed data to use in pipeline. see OutputFileDatasetConfig doc from azure\n",
    "parser.add_argument('--prepped_data', type=str, dest='prepped_data')\n",
    "parser.add_argument('--factors', type=int, dest='factors')\n",
    "parser.add_argument('--regularization', type=float, dest='reg')\n",
    "parser.add_argument('--iterations', type=int, dest='iterations')\n",
    "args = parser.parse_args()\n",
    "\n",
    "#set parameters\n",
    "save_folder = args.prepped_data\n",
    "factors = args.factors\n",
    "reg = args.reg\n",
    "iterations = args.iterations\n",
    "\n",
    "#get the experiment run context and workspace\n",
    "run = Run.get_context()\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "#load data\n",
    "print('loading data...')\n",
    "#frame = Dataset.get_by_name(ws, dataset_name).to_pandas_dataframe()\n",
    "# Get the training data path from the input. must be passed as argument in the script as as_named_input + as_download or as_mount\n",
    "data_path = run.input_datasets['clicks']\n",
    "\n",
    "#declare reco object with parameters\n",
    "reco = Recommender(data_path, factors = factors, regularization=reg, iterations=iterations)\n",
    "\n",
    "print('start preperation...')\n",
    "\n",
    "#load, clean and prepare data\n",
    "reco.to_matrix()\n",
    "\n",
    "print('sparse matrix ok')\n",
    "\n",
    "#prepare matrix for training and dictionary to calculate hit rate\n",
    "reco.make_train_2()\n",
    "\n",
    "#save the prepped data\n",
    "print('saving data..')\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "train_path = os.path.join(save_folder, 'train.npz')\n",
    "user_item_path = os.path.join(save_folder, 'user_item_altered.pkl')\n",
    "object_path = os.path.join(save_folder, 'reco.pkl')\n",
    "\n",
    "#save matrix and dictionnary\n",
    "sparse.save_npz(train_path, reco.train)\n",
    "joblib.dump(reco.user_item_altered, user_item_path)\n",
    "\n",
    "#save object reco\n",
    "joblib.dump(reco, object_path)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00b5b64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_azure/train_recommender_class.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_azure/train_recommender_class.py\n",
    "\n",
    "print('print importing lib...')\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Run, Model\n",
    "from azureml.core import Dataset\n",
    "from scipy import sparse\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from class_recommender import Recommender\n",
    "\n",
    "\n",
    "print('lib imported...')\n",
    "\n",
    "#get scripts arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--training-data\", type=str, dest='training_data', help='training data')\n",
    "args = parser.parse_args()\n",
    "\n",
    "save_folder = args.training_data\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the prepared data file in the training folder\n",
    "print('loading object..')\n",
    "\n",
    "object_path = os.path.join(save_folder, 'reco.pkl')\n",
    "\n",
    "\n",
    "reco = joblib.load(object_path)\n",
    "\n",
    "print('object loaded..')\n",
    "\n",
    "#fit model \n",
    "reco.fit()\n",
    "\n",
    "print('fitted..')\n",
    "\n",
    "#evaluate \n",
    "HR, ARHR = reco.predict_evaluate()\n",
    "\n",
    "print(\"Hit Rate of:\", HR)\n",
    "print(\"Average Reciprocal Hit Rate of:\", ARHR)\n",
    "run.log('HR', np.float(HR))\n",
    "run.log('ARHR', np.float(ARHR))\n",
    "\n",
    "#save the trained model in the outputs folder\n",
    "print(\"saving model..\")\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "model_file = os.path.join('outputs', 'recommender_model.pkl')\n",
    "joblib.dump(value=reco.model, filename=model_file)\n",
    "\n",
    "#register the model\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "              model_path = model_file,\n",
    "              model_name = 'recommender_model',\n",
    "              properties={'Hit Rate': np.float(HR),\n",
    "                         \"Average Reciprocal Hit Rate\": np.float(ARHR)})\n",
    "\n",
    "run.complete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6f832c",
   "metadata": {},
   "source": [
    "## Pipiline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec948c5",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bdcac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import RunConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf9f480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment folder\n",
    "experiment_folder = 'training_azure'\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "#assign compute\n",
    "pipeline_run_config.target = training_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = env_p8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f407ad62",
   "metadata": {},
   "source": [
    "### Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bafc3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ef947f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class OutputFileDatasetConfig: This is an experimental class, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n",
      "Class OutputDatasetConfig: This is an experimental class, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n"
     ]
    }
   ],
   "source": [
    "# Get the training dataset\n",
    "clicks_ds = ws.datasets.get(\"clicks\")\n",
    "\n",
    "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\n",
    "#with no specification in OutputFileDatasetConfig for destination it will be in workspaceblobstore datastore\n",
    "prepped_data = OutputFileDatasetConfig(\"prepped_data\")\n",
    "\n",
    "#step1, run the data prep script\n",
    "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"data_prep_class.py\",\n",
    "                                arguments = ['--prepped_data', prepped_data,\n",
    "                                             '--iterations',30,\n",
    "                                             '--regularization',0.5,\n",
    "                                             '--factors',20,\n",
    "                                             '--input-data', clicks_ds.as_named_input('clicks').as_download()],\n",
    "                                compute_target = training_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "# Step 2, run the training script\n",
    "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"train_recommender_class.py\",\n",
    "                                arguments = ['--training-data', prepped_data.as_input()],\n",
    "                                compute_target = training_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fc1b3c",
   "metadata": {},
   "source": [
    "### build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8953ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "297b6725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Prepare Data [423cd832][4e31d3f4-acc1-4d09-a4e7-c61e6cbe856f], (This step will run and generate new outputs)\n",
      "Created step Train and Register Model [9e266bc3][73383757-66aa-406c-b872-c0978f5b913f], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 6d5be208-2132-478b-bfe4-14b27ffe4757\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/recommender-pipeline/runs/6d5be208-2132-478b-bfe4-14b27ffe4757?wsid=/subscriptions/b9053cbf-be55-4e83-8c03-d6b0eb90cb5a/resourcegroups/Projet_7/workspaces/projet_7\n",
      "PipelineRunId: 6d5be208-2132-478b-bfe4-14b27ffe4757\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/recommender-pipeline/runs/6d5be208-2132-478b-bfe4-14b27ffe4757?wsid=/subscriptions/b9053cbf-be55-4e83-8c03-d6b0eb90cb5a/resourcegroups/Projet_7/workspaces/projet_7\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected a StepRun object but received <class 'azureml.core.run.Run'> instead.\n",
      "This usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\n",
      "Please check for package conflicts in your python environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '6d5be208-2132-478b-bfe4-14b27ffe4757', 'status': 'Completed', 'startTimeUtc': '2021-09-06T04:48:52.574076Z', 'endTimeUtc': '2021-09-06T08:05:29.001606Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.6d5be208-2132-478b-bfe4-14b27ffe4757/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=GwivjlrJ%2F5BgrSHvQI2CX3dEP3e6A9MGSMqsbmdhQZI%3D&skoid=781a4368-8669-4ef7-a3f9-be394693522d&sktid=33e47288-d1e1-43e8-b65b-4ba7bfd37a9f&skt=2021-09-06T18%3A24%3A53Z&ske=2021-09-07T18%3A24%3A52Z&sks=b&skv=2019-07-07&st=2021-09-06T18%3A14%3A56Z&se=2021-09-07T02%3A24%3A56Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.6d5be208-2132-478b-bfe4-14b27ffe4757/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=N0mW3OOa%2Bq%2FtP7i8QVbaGzn4fnBun0YIbjH2FZCWMkc%3D&skoid=781a4368-8669-4ef7-a3f9-be394693522d&sktid=33e47288-d1e1-43e8-b65b-4ba7bfd37a9f&skt=2021-09-06T18%3A24%3A53Z&ske=2021-09-07T18%3A24%3A52Z&sks=b&skv=2019-07-07&st=2021-09-06T18%3A14%3A56Z&se=2021-09-07T02%3A24%3A56Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://stockageprojet7opcr.blob.core.windows.net/azureml/ExperimentRun/dcid.6d5be208-2132-478b-bfe4-14b27ffe4757/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=98LNSyp5Wa60CTTHcFqT6OsUcQTDjzrKGtIdDT99ar8%3D&skoid=781a4368-8669-4ef7-a3f9-be394693522d&sktid=33e47288-d1e1-43e8-b65b-4ba7bfd37a9f&skt=2021-09-06T18%3A24%3A53Z&ske=2021-09-07T18%3A24%3A52Z&sks=b&skv=2019-07-07&st=2021-09-06T18%3A14%3A56Z&se=2021-09-07T02%3A24%3A56Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the pipeline\n",
    "pipeline_steps = [prep_step, train_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace=ws, name = 'recommender-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "\n",
    "\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7d503f",
   "metadata": {},
   "source": [
    "### Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f78a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Register Model :\n",
      "\t HR : 0.238649736760607\n",
      "\t ARHR : 0.09021601729367221\n",
      "Prepare Data :\n"
     ]
    }
   ],
   "source": [
    "#run\n",
    "for run in pipeline_run.get_children():\n",
    "    print(run.name, ':')\n",
    "    metrics = run.get_metrics()\n",
    "    for metric_name in metrics:\n",
    "        print('\\t',metric_name, \":\", metrics[metric_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bc1fd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommender_model version: 5\n",
      "\t Hit Rate : 0.234050789718179\n",
      "\t Average Reciprocal Hit Rate : 0.08945525913472578\n",
      "\n",
      "\n",
      "recommender_model version: 4\n",
      "\t Hit Rate : 0.22587488386497367\n",
      "\t Average Reciprocal Hit Rate : 0.08510939427902889\n",
      "\n",
      "\n",
      "recommender_model version: 3\n",
      "\t Hit Rate : 0.04225352112676056\n",
      "\t Average Reciprocal Hit Rate : 0.014769170579029735\n",
      "\n",
      "\n",
      "recommender_model version: 2\n",
      "\t Hit Rate : 0.238649736760607\n",
      "\t Average Reciprocal Hit Rate : 0.09021601729367221\n",
      "\n",
      "\n",
      "recommender_model version: 1\n",
      "\t Hit Rate : 0.056338028169014086\n",
      "\t Average Reciprocal Hit Rate : 0.017331768388106416\n",
      "\n",
      "\n",
      "glove_sample version: 4\n",
      "\t max_l : 45\n",
      "\n",
      "\n",
      "glove_sample version: 3\n",
      "\t max_l : 45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model registered\n",
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6f54c",
   "metadata": {},
   "source": [
    "### Publish pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd69e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
